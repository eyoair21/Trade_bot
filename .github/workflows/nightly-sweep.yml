name: Nightly Sweep

on:
  schedule:
    - cron: "17 3 * * *"  # 03:17 UTC daily
  workflow_dispatch:  # Manual trigger
  push:
    branches: [main]

# Permissions for GitHub Pages deployment
permissions:
  contents: write  # For badge commits
  pages: write     # For Pages deployment
  id-token: write  # For Pages deployment authentication

jobs:
  nightly-sweep:
    name: Nightly Sweep (CI Smoke)
    runs-on: ubuntu-latest
    # Skip if this is a badge commit from github-actions[bot]
    if: github.actor != 'github-actions[bot]'
    outputs:
      run_id: ${{ steps.set-run-id.outputs.run_id }}
      regress_passed: ${{ steps.regress.outcome == 'success' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Needed for git SHA
          token: ${{ secrets.GITHUB_TOKEN }}  # Needed for push

      - name: Set run ID
        id: set-run-id
        run: |
          RUN_ID="${{ github.run_id }}-$(echo ${{ github.sha }} | cut -c1-7)"
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "Run ID: $RUN_ID"

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy pyarrow python-dotenv pyyaml
          pip install pytest pytest-cov ruff black mypy
          pip install matplotlib  # For trend plots

      - name: Download previous trend data
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: nightly-sweep.yml
          name: trend-data
          path: runs/sweeps/
        continue-on-error: true  # OK if no previous data exists

      - name: Generate sample data
        run: |
          python scripts/make_sample_data.py

      - name: Run CI smoke sweep
        run: |
          python -m traderbot.cli.sweep sweeps/ci_smoke.yaml --workers 2 --time

      - name: Generate leaderboard
        run: |
          python -m traderbot.cli.leaderboard runs/sweeps/ci_smoke

      - name: Run regression comparison
        id: regress
        run: |
          python -m traderbot.cli.regress compare \
            --no-emoji \
            --html \
            --reruns 3 \
            --variance-threshold 0.15 \
            --current runs/sweeps/ci_smoke \
            --baseline benchmarks/baseline.json \
            --budget sweeps/perf_budget.yaml \
            --out runs/sweeps/ci_smoke/regression_report.md
        continue-on-error: true

      - name: Generate summary.json
        if: always()
        run: |
          # Generate summary.json from baseline_diff.json
          python -c "
          import json
          from datetime import datetime, timezone
          from pathlib import Path

          diff_path = Path('runs/sweeps/ci_smoke/baseline_diff.json')
          summary_path = Path('runs/sweeps/ci_smoke/summary.json')

          if diff_path.exists():
              diff_data = json.loads(diff_path.read_text())
              summary = {
                  'schema_version': '1',
                  'run_id': '${{ steps.set-run-id.outputs.run_id }}',
                  'verdict': 'PASS' if diff_data.get('passed', False) else 'FAIL',
                  'sharpe_delta': round(diff_data.get('sharpe_delta', diff_data.get('metric_delta', 0.0)), 6),
                  'trades_delta': None,
                  'timing_p90': round(diff_data.get('timing', {}).get('current', {}).get('p90', 0.0), 3),
                  'git_sha': '${{ github.sha }}',
                  'generated_utc': datetime.now(timezone.utc).isoformat()
              }
              summary_path.write_text(json.dumps(summary, indent=2))
              print(f'Generated summary.json: {summary[\"verdict\"]}')
          else:
              print('baseline_diff.json not found, skipping summary.json')
          "
        continue-on-error: true

      - name: Generate trend plots
        if: always()
        run: |
          python scripts/generate_trend_plots.py \
            --trend-file runs/sweeps/trend_data.json \
            --current-diff runs/sweeps/ci_smoke/baseline_diff.json \
            --output-dir runs/sweeps/ci_smoke/plots \
            --git-sha ${{ github.sha }}
        continue-on-error: true

      - name: Generate status badge
        if: always()
        run: |
          python scripts/generate_status_badge.py \
            --from-diff runs/sweeps/ci_smoke/baseline_diff.json \
            --output badges/regression_status.svg \
            --sha ${{ github.sha }}
        continue-on-error: true

      - name: Upload status badge
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: status-badge
          path: badges/regression_status.svg
          retention-days: 30

      - name: Commit badge to repo (main branch + PASS only)
        if: github.ref == 'refs/heads/main' && steps.regress.outcome == 'success'
        run: |
          # Configure git for github-actions[bot]
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Check if badge file changed
          if git diff --quiet badges/regression_status.svg 2>/dev/null; then
            echo "Badge unchanged, skipping commit"
          else
            git add badges/regression_status.svg
            git commit -m "chore: update regression badge [ci skip]"
            git push
            echo "Badge committed and pushed"
          fi

      - name: Run determinism check (1 rerun)
        if: steps.regress.outcome == 'success'
        run: |
          python -m traderbot.cli.sweep sweeps/ci_smoke.yaml --workers 1 --rerun-best 1
        continue-on-error: true

      - name: Pack sweep artifacts
        run: |
          python scripts/pack_sweep.py runs/sweeps/ci_smoke --output ci_smoke.zip --max-size-mb 80

      - name: Upload sweep artifacts
        uses: actions/upload-artifact@v4
        with:
          name: nightly-sweep-${{ github.sha }}
          path: ci_smoke.zip
          retention-days: 7

      - name: Upload regression report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression-report-${{ github.sha }}
          path: |
            runs/sweeps/ci_smoke/regression_report.md
            runs/sweeps/ci_smoke/regression_report.html
            runs/sweeps/ci_smoke/baseline_diff.json
            runs/sweeps/ci_smoke/provenance.json
            runs/sweeps/ci_smoke/summary.json
            runs/sweeps/ci_smoke/variance_report.json
            runs/sweeps/ci_smoke/determinism.json
            runs/sweeps/ci_smoke/plots/
          retention-days: 14

      - name: Upload trend data (for next run)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trend-data
          path: runs/sweeps/trend_data.json
          retention-days: 90

      - name: Check regression status
        if: steps.regress.outcome == 'failure'
        run: |
          echo "::warning::Regression check failed - review regression_report.md"

      - name: Check for exceptional performance (manual dispatch only)
        if: github.event_name == 'workflow_dispatch'
        run: |
          # Extract best Sharpe from leaderboard
          if [ -f runs/sweeps/ci_smoke/leaderboard.csv ]; then
            best_sharpe=$(tail -1 runs/sweeps/ci_smoke/leaderboard.csv | cut -d',' -f4)
            echo "Best Sharpe: $best_sharpe"
            # Note: Actual release creation would go here if Sharpe > 0.8
          fi

      - name: Update baseline (manual dispatch with better performance)
        if: github.event_name == 'workflow_dispatch' && steps.regress.outcome == 'success'
        run: |
          # Only update baseline if regression passed and this is a manual run
          python -m traderbot.cli.regress update-baseline \
            --no-emoji \
            --current runs/sweeps/ci_smoke \
            --out benchmarks/baseline_candidate.json
          echo "New baseline candidate created - review before merging"

  # ============================================================
  # Deploy reports to GitHub Pages (main branch + PASS only)
  # ============================================================
  deploy-pages:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    needs: nightly-sweep
    # Only deploy on main branch, when regression passed, and not triggered by bot
    if: github.ref == 'refs/heads/main' && needs.nightly-sweep.outputs.regress_passed == 'true' && github.actor != 'github-actions[bot]'

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Download regression report artifact
        uses: actions/download-artifact@v4
        with:
          name: regression-report-${{ github.sha }}
          path: downloaded-reports/

      - name: Checkout gh-pages branch
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages-checkout
        continue-on-error: true

      - name: Prepare Pages directory
        id: prepare-pages
        run: |
          RUN_ID="${{ needs.nightly-sweep.outputs.run_id }}"
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          echo "Preparing reports for run: $RUN_ID"

          # Create public directory structure
          mkdir -p public/reports/$RUN_ID
          mkdir -p public/reports/latest

          # Copy reports to run-specific directory
          if [ -d downloaded-reports ]; then
            # Handle nested directory from artifact
            if [ -d downloaded-reports/runs/sweeps/ci_smoke ]; then
              cp -r downloaded-reports/runs/sweeps/ci_smoke/* public/reports/$RUN_ID/ 2>/dev/null || true
            else
              cp -r downloaded-reports/* public/reports/$RUN_ID/ 2>/dev/null || true
            fi
          fi

          # Minify HTML files to reduce file size
          echo "Minifying HTML files..."
          python scripts/dev/minify_html.py --input-dir public/reports/$RUN_ID --pattern "*.html"

          # Generate SHA256 integrity hashes for run directory (after minification)
          echo "Generating sha256sums.txt..."
          python scripts/dev/generate_sha256sums.py --report-dir public/reports/$RUN_ID

          # Copy to latest (atomic replacement)
          rm -rf public/reports/latest/*
          cp -r public/reports/$RUN_ID/* public/reports/latest/ 2>/dev/null || true

          # Copy existing manifest and reports from gh-pages if available
          if [ -f gh-pages-checkout/reports/manifest.json ]; then
            cp gh-pages-checkout/reports/manifest.json public/reports/manifest.json
          else
            echo '{"runs": [], "updated": null, "latest": null}' > public/reports/manifest.json
          fi

          # Copy existing report directories from gh-pages (for history)
          if [ -d gh-pages-checkout/reports ]; then
            for dir in gh-pages-checkout/reports/*/; do
              dirname=$(basename "$dir")
              # Skip latest and manifest
              if [ "$dirname" != "latest" ] && [ "$dirname" != "$RUN_ID" ]; then
                if [ ! -d "public/reports/$dirname" ]; then
                  cp -r "$dir" "public/reports/$dirname" 2>/dev/null || true
                fi
              fi
            done
          fi

          # Update manifest, generate index with prune policy, and build history.json
          echo "Updating manifest, building history, and pruning old reports..."
          python scripts/dev/update_pages_index.py \
            --manifest public/reports/manifest.json \
            --run-id "$RUN_ID" \
            --timestamp "$TIMESTAMP" \
            --status pass \
            --max-runs 50 \
            --prune \
            --reports-dir public/reports \
            --index-out public/reports/index.html \
            --history-out public/reports/history.json

          # Generate Atom feed from history.json
          echo "Generating Atom feed..."
          python scripts/dev/make_feed.py \
            --history public/reports/history.json \
            --out public/reports/feed.xml \
            --base-url "https://eyoair21.github.io/Trade_Bot" \
            --max-entries 20

          # Generate top-level integrity hashes (for index, history, feed)
          echo "Generating top-level sha256sums.txt..."
          python scripts/dev/generate_sha256sums.py \
            --report-dir public/reports \
            --top-level \
            --output sha256sums_root.txt

          # Create root redirect
          cat > public/index.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <meta http-equiv="refresh" content="0; url=reports/">
              <title>TraderBot Reports</title>
          </head>
          <body>
              <p>Redirecting to <a href="reports/">regression reports</a>...</p>
          </body>
          </html>
          EOF

          # Create 404.html
          cat > public/404.html << 'EOF'
          <!DOCTYPE html>
          <html lang="en" data-theme="light">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>404 - Not Found | TraderBot Reports</title>
              <style>
                  :root { --bg: #f5f5f5; --text: #333; --link: #0366d6; }
                  [data-theme="dark"] { --bg: #1a1a2e; --text: #e4e4e7; --link: #58a6ff; }
                  body { font-family: system-ui, sans-serif; max-width: 600px; margin: 0 auto;
                         padding: 4rem 2rem; background: var(--bg); color: var(--text); text-align: center; }
                  h1 { font-size: 4rem; margin: 0; color: var(--link); }
                  a { color: var(--link); }
                  .btn { display: inline-block; margin: 0.5rem; padding: 0.75rem 1.5rem;
                         background: var(--link); color: white; text-decoration: none; border-radius: 6px; }
              </style>
          </head>
          <body>
              <h1>404</h1>
              <h2>Page Not Found</h2>
              <p>The report you're looking for doesn't exist or has been pruned.</p>
              <div><a href="/Trade_Bot/reports/" class="btn">All Reports</a>
                   <a href="/Trade_Bot/reports/latest/regression_report.html" class="btn">Latest</a></div>
          </body>
          </html>
          EOF

          # Create robots.txt
          cat > public/robots.txt << 'EOF'
          User-agent: *
          Allow: /
          EOF

          # Create .nojekyll
          touch public/.nojekyll

          # List what we're deploying
          echo "=== Pages content ==="
          find public -type f | head -30

          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Add Pages URL to Job Summary
        run: |
          RUN_ID="${{ steps.prepare-pages.outputs.run_id }}"
          echo "## GitHub Pages Deployment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Reports published to GitHub Pages:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Latest Report:** https://eyoair21.github.io/Trade_Bot/reports/latest/regression_report.html" >> $GITHUB_STEP_SUMMARY
          echo "- **This Run:** https://eyoair21.github.io/Trade_Bot/reports/$RUN_ID/regression_report.html" >> $GITHUB_STEP_SUMMARY
          echo "- **All Reports:** https://eyoair21.github.io/Trade_Bot/reports/" >> $GITHUB_STEP_SUMMARY
          echo "- **Atom Feed:** https://eyoair21.github.io/Trade_Bot/reports/feed.xml" >> $GITHUB_STEP_SUMMARY
          echo "- **History Data:** https://eyoair21.github.io/Trade_Bot/reports/history.json" >> $GITHUB_STEP_SUMMARY
